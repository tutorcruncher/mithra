worker_processes 1;

user nobody nogroup;
pid /tmp/nginx.pid;
error_log /dev/stdout crit;

events {
  worker_connections 1024; # increase if you have lots of clients
  accept_mutex off; # set to 'on' if nginx worker_processes > 1
  use epoll;
}

http {
  include mime.types;
  # fallback in case we can't determine a type
  default_type application/octet-stream;

  log_format custom '$remote_addr request="$request" status=$status time=${request_time}s '
                    'request_size=$request_length response_size=$body_bytes_sent '
                    'referrer="$http_referer"';
  access_log /dev/stdout custom;
  sendfile on;

  upstream app_server {
    # fail_timeout=0 means we always retry an upstream event if it failed
    # to return a good HTTP response
    # for a TCP configuration
    server web:8000 fail_timeout=0;
  }

  upstream js_server {
    server js:80 fail_timeout=0;
  }

  server {
    listen 80 default_server;

    client_max_body_size 4G;

    keepalive_timeout 5;

    location /api/ {
      proxy_set_header Host $http_host;
      proxy_set_header Upgrade $http_upgrade;
      proxy_http_version 1.1;
      proxy_set_header Connection "upgrade";
      proxy_redirect off;

      # 600 will mean websocket connections disconnect,
      # this is intentional, ws clients should be resilient enough to reconnect
      proxy_send_timeout 600;
      proxy_read_timeout 600;
      proxy_connect_timeout 3;

      proxy_pass http://app_server;
    }

    location /pgweb/ {
      access_log off;
      rewrite /pgweb(/.*) $1 break;
      proxy_pass http://pgweb;
    }

    location / {
      proxy_redirect off;
      proxy_pass http://js_server;
    }
  }
}
